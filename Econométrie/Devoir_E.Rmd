---
title: "Projet Econométrie"
subtitle: "**Etude de la base de données portant sur le prix des logements**"
author: "Léa BRASSEUR & Neil DUPIN"
date: ' '
lang: "fr"
fontsize: 11pt
geometry: a4paper,top=2cm,bottom=2cm,left=1.5cm,right=1.5cm
header-includes: 
- \usepackage{float} 
- \floatplacement{figure}{H} 
- \floatplacement{table}{H} 
output:
  html_document: 
    toc: true
    toc_float: true
    number_section: false
    highlight: "espresso"
    theme: flatly
    df_print: paged
    dev: png
  pdf_document: 
    toc: false
    number_section: true 
    keep_tex: true
editor_options: 
  chunk_output_type: console
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, fig.align="center")
```

```{r, echo = FALSE}
library(readxl)
library(stargazer)
library(lmtest)
library(ggplot2)
library(knitr)
library(dplyr)
library(kableExtra)
library(gridExtra)
library(GGally)
library(corrplot)
library(ggcorrplot)
library(nortest)
library(performance)
library(Hmisc)
library(olsrr)
```

```{r, echo = FALSE}
data = read.csv("BDD_data.csv")
```

<span style="color:red"> Dans un premier temps, nous voyons que la base de données porte sur les logements et leurs différentes caractéristiques. Le but de cette étude va être de déterminer quelles variables influencent le prix des logements. </span>

# La base de données

### *Statistiques descriptives* 

```{r, echo = FALSE}
summary(data)
describe(data)
```

### *Première visualisation des variables*

Nous partons du principe qu'il n'est pas nécessaire de conserver les variables id et date puisqu'elles n'ont pas de lien avec le prix.

```{r, echo = FALSE}
data$id = NULL
data$date = NULL
```

```{r, echo = FALSE}
a <- ggplot(data, aes(x=floors))+
  geom_bar(width=0.3, fill="cornflowerblue")+
  ggtitle("Répartition des étages")+
  labs(x="Nombre d'étage", y="effectifs") + scale_x_continuous(breaks = c(1,1.5,2,2.5,3,3.5))
```

```{r, echo = FALSE}
b <- ggplot(data, aes(x=yr_built))+
  geom_bar(width=0.3, fill="deeppink")+
  ggtitle("Répartition des années de construction")+
  labs(x="Année de construction", y="effectifs")
```

```{r, echo = FALSE}
c <- ggplot(data, aes(x=waterfront))+
  geom_bar(width=0.5, fill="firebrick")+
  ggtitle("Maison au bord de l'eau")+
  labs(x="Non / Oui", y="effectifs")
```

```{r, echo = FALSE}
d <- ggplot(data, aes(data$price)) + stat_bin(bins = 100, colour="black", fill="burlywood") +labs(x= "Prix",y= "Frequence" , title = "Répartition des prix de vente") + xlim(0,4000000) +
  scale_fill_discrete()
```

```{r, echo = FALSE}
e <- ggplot(data, aes(data$bedrooms)) + stat_bin(bins = 13, colour="black", fill="coral1") + labs(x= "nombre de chambre",y= "Frequence" , title = "Répartition du nombre de chambre") + xlim(0,10)  + scale_fill_discrete() 
```

```{r, echo = FALSE}
f <- qplot(data$view, main = "House View" , xlab = "View" , ylab = "Frequence")
```

```{r, echo = FALSE}
g <- ggplot(data, aes(data$sqft_lot)) + stat_bin(bins = 30, colour="black", fill="gold2") +
  labs(x= "Sqft Lot",y= "Frequence" , title = "Histogramme de Sqft Lot") + xlim(0, 120000) +
   scale_fill_discrete()
```

```{r, echo = FALSE}
h <- ggplot(data, aes(data$sqft_above)) + stat_bin(bins = 30, colour="black", fill="khaki4") +
  labs(x= "Sqft Above",y= "Frequence" , title = "Histogramme de Sqft Above") + xlim(0, 8000) + scale_fill_discrete()
```

```{r, echo = FALSE,  fig.height = 14, fig.width = 18}
grid.arrange(a,b,c,d,e,f,g,h, nrow=4)
```

- La répartition des étages n'est pas vraiment homogène, la plupart des maisons ont 1 ou 2 étages. 
- La majorité des maisons ont été construites après les années 1950.
- Très peu de maison sont au bord de l'eau.
- La plupart de maisons possèdent 3 ou 4 chambres. 
- Pour la majorité des logements, la variable view est égale à 0.
- La variable sqft_above suit la même tendance que sqft_lot.

### *Corrélation* 

```{r}
as.dist(round(cor(data),2))
```

```{r, fig.height = 10, fig.width = 14 }
num_plot<- corrplot(cor(data),method= "number")
```

Nous pouvons voir grâce à cette matrice que la variable sqft_living est fortement corrélée avec les variables price, grade et sqft_above.

### *Relation avec le prix* 

```{r, echo = FALSE, fig.height = 8, fig.width = 12}
par(mfrow=c(3,2))
scatter.smooth(x=data$price, y=data$bedrooms, main="Price ~ Bedrooms",xlab = "Price", ylab= "Bedrooms")
scatter.smooth(x=data$price, y=data$bathrooms, main = "Price ~ Bathrooms", xlab = "Price", ylab = "Bathrooms")
scatter.smooth(x=data$price, y=data$sqft_living, main ="Price ~ Sqft Living", xlab = "Price", ylab = "Sqft_living")
scatter.smooth(x=data$price, y=data$floors, main = "Price ~ Floors", xlab = "Price", ylab = "Floors")
scatter.smooth(x=data$price, y=data$condition, main = "Price ~ Condition", xlab = "Price", ylab = "Condition")
scatter.smooth(x=data$price, y=data$grade, main = "Price ~ Grade", xlab = "Price", ylab = "Grade")
scatter.smooth(x=data$price, y=data$sqft_above, main = "Price ~ Sqft Above", xlab = "Price", ylab = "Sqft_above")
scatter.smooth(x=data$price, y=data$sqft_basement, main = "Price ~ Sqft Basement", xlab = "Price", ylab = "Sqft_basement")
```

Nous supprimons les variables qui n'ont pas de lien avec le prix d'après la matrice de corrélation et les graphiques précédents et celles qui ne nous semblent pas pertinentes. 

```{r}
data2 <- data[,c(-5,-6,-7,-8,-9,-12,-13,-14,-15,-16,-17,-18,-19)]
```

Il ne nous reste plus que les variables price, bedrooms, bathrooms, sqft_living, grade et sqft_above.

### *Valeurs aberrantes*

Puis, nous faisons quelques tests pour trouver les valeurs qui peuvent nous sembler aberrantes. 

```{r}
table(data2$bedrooms)
```

```{r}
sup <- which(data2$bedrooms==11 | data2$bedrooms==33)
```

```{r}
databis <- data2[-sup,]
```

# Régression linéaire 1

Nous faisons notre première régression avec les variables les plus corrélées au prix. 

```{r}
databis_lm <- lm(formula = price ~ bedrooms + bathrooms + sqft_living + grade + sqft_above, data = databis)
```

# Analyse de la régression 1 

```{r}
summary(databis_lm)
```

### *Les coefficients*

Nous pouvons voir que les p-value pour les coefficients associés aux variables : bedrooms, bathrooms, sqft_living, grade et sqft_above sont inférieures à 0.001. Ce qui veut dire que nous rejettons l'hypothèse nulle et que les coefficients sont significativement différents de 0. 
Nous pouvons interpréter cela en disant qu'une augmentation d'une unité de la variable bedrooms (une chambre en plus) fait baisser le prix de la maison de 5.167e+05 (toutes choses égales par ailleurs). Ou bien, l'augmentation d'une unité de la variable bathrooms (une salle de bain en plus), fait baisser le prix de 2.411e+04. 

### *R²*

Nous observons un **R² = 0.551**, ce qui veut dire que le modèle explique 55.1% de la variabilité des prix des maisons. Ce modèle a une qualité d'ajustement moyenne puisque le R² se trouve toujours entre 0 et 1. Pour le R² ajusté, il est presque égal au R². 

### *Significativé globale du modèle* 

<span style="color:blue">**p-value < 2.2e-16 < alpha = 0.01**</span>

Ce qui veut dire que nous rejettons l'hypothèse nulle et donc le modèle est globalement significatif. 

### *Les résidus* 

Pour accepter les résultats d'une régression, il faut que les résidus soient identiquement distribués et de manière aléatoire. Ils  doivent également être homoscédastiques, être indépendants et suivre une loi normale.

```{r, fig.height = 6, fig.width = 10}
par(mfrow=c(2,2))
plot(databis_lm)
```

- *Normalité*

```{r}
pearson.test(databis_lm$residuals)
```

<span style="color:blue">**p-value < 2.2e-16 < alpha = 0.01**</span>

Nous rejettons H0, l'hypothèse de normalité des résidus. 

D'après le test de Pearson, nous pouvons conclure que les résidus ne suivent pas une loi normale. 
De plus, nous pouvons également le remarquer sur le graphique "Normal Q-Q" car les points ne se trouvent pas tous sur la droite. 

- *Homoscédasticité*

```{r}
bptest(databis_lm)
```

<span style="color:blue">**p-value < 2.2e-16 < alpha = 0.01**</span>

D'après le test, on rejette H0. Ce qui veut dire que les variances ne sont pas constantes, elles sont hétéroscédastiques. 

De plus, nous voyons, grâce au graphique "Scale-Location" que la droite de tendance n'est pas horizontale ce qui nous montre bien qu'il y a une tendance particulière au niveau de la distribution des résidus.

- *Linéarité*

D'après le graphique "Residuals vs Fitted", nous pouvons voir que les résidus ont tendance, pour la plupart, à se regrouper et donc qu'ils ne sont pas distribués aléatoirement. L'hypothèse de linéarité est donc rejettée. 

- *Valeurs aberrantes* 

Nous pouvons voir sur le graphique "Residuals vs Leverage" que certaines valeurs se distinguent et ne font pas parties du nuage de points. Ces valeurs peuvent être qualifiées de valeurs aberrantes. 
 
```{r}
plot(databis_lm, 4)
```

Nous pouvons voir que la distance de Cook ne dépasse jamais 1. Cependant, nous distiguons 3 valeurs qui ont une tendance différente de celles des autres.

### *Conclusion* 

Les résultats ne peuvent pas être acceptés puisque les résidus ne suivent pas une loi normale, ils ne sont pas homoscédastiques et ils ne sont pas distribués aléatoirement.

```{r}
model_performance(databis_lm)
```

De plus, nous pouvons voir que le AIC, le BIC ainsi que le RMSE (erreur quadratique moyenne) sont très élevés ce qui signifie que le modèle est mal ajusté.

# Régression linéaire 2 

### *Les effets d'interractions* 

Nous regardons les effets d'interractions pour savoir si toutes les variables sont nécessaires pour notre modèle suivant. 

```{r}
interact <- lm(formula = price ~ yr_built + yr_renovated + yr_built*yr_renovated, data = data)
```

```{r}
stargazer(interact, use = "complete.obs", type = "text", keep.stat = c("n"))
```

Nous pouvons voir qu'il y a un léger effet d'interraction entre ces 2 variables puisque le coefficients yr_built:yr_renovated est égal à **0.361**. Mais ce n'est pas assez pour pouvoir retirer l'une des variables de la régression. 

```{r}
interact2 <- lm(formula = price ~ sqft_lot + sqft_lot15 + sqft_lot*sqft_lot15, data = data)
```

```{r}
stargazer(interact2, use = "complete.obs", type = "text", keep.stat = c("n"))
```

Nous pouvons voir qu'il n'y aucun effet d'interraction entre ces 2 variables, elles sont donc toutes les deux nécessaires au modèle. 

### *Régression 2*

Pour notre deuxième modèle nous avons décidé d'inclure quasiment toutes les variables à notre disposition sauf id et date qui ne sont pas pertinents, sqft_above car il y a une forte corrélation  avec sqft_living (0.88), il n'est donc pas nécessaire de mettre les 2 variables dans le modèle. Nous avons également enlevés waterfront car il y a très peu de oui et view car la quasi totalité des réponses vaut 1. 

```{r}
data_lm <- lm(formula = price ~ bedrooms + bathrooms + sqft_living + sqft_lot + floors + condition + grade + sqft_basement + yr_built + yr_renovated + zipcode + lat + long + sqft_living15 + sqft_lot15, data = data)
```

```{r}
summary(data_lm)
```

# Analyse de la régression 2

### *Les coefficients*

Les p-value associées à chaque coefficient sont inférieures à leur alpha respectifs, ce qui veut donc dire que toutes les coefficients sont significativement différents de 0. Les variables ont toutes un impact sur le prix. 

### *R²*

Ce modèle a un **R² = 0.6616** ce qui veut dire que le modèle explique 66.16% de la variabilité des prix des maisons. 

### *Significativé globale du modèle* 

<span style="color:brown">**p-value < 2.2e-16 < alpha = 0.01**</span>

Grâce au test de Fisher, nous pouvons dire que le modèle est globalement significatif. 

### *Les résidus* 

```{r, fig.height = 6, fig.width = 10}
par(mfrow=c(2,2))
plot(data_lm)
```

- *Normalité*

```{r}
pearson.test(data_lm$residuals)
```

<span style="color:brown">**p-value < 2.2e-16 < alpha = 0.01**</span>

D'après le graphique "Normal Q-Q" et le test de Pearson, nous pouvons conclure que les résidus ne suivent pas une loi normale. 

- *Homoscédasticité*

```{r}
bptest(data_lm)
```

<span style="color:brown">**p-value < 2.2e-16 < alpha = 0.01**</span>

Nous voyons avec le test et le graphique que l'hypothèse nulle d'homoscédasticité est rejettée. 

- *Linéarité*

Sur le graphique "Residuals vs Fitted" les résidus sont regroupés, ils ne sont pas distribués aléatoirement. 

- *Valeurs aberrantes*

Tout comme dans le modèle précédent il est visible que certaines valeurs se distinguent des autres. 
 
```{r}
plot(data_lm, 4)
```

Nous pouvons voir que la distance de Cook ne dépasse jamais 1. Cependant, nous distiguons 4 valeurs qui ont une tendance différente de celles des autres.

### *Conclusion* 

Les résultats de la régression ne peuvent pas être acceptés car les résidus ne sont pas conformes. 

```{r}
model_performance(data_lm)
```

Nous voyons que le AIC, le BIC et le RMSE sont encore très élevés, mais moins que pour le modèle précédent. De plus, le R² a augmenté.

# Spécification du modèle 

Nous décidons de faire une troisième régression dans le but d'avoir des résultats plus cohérents et un meilleur R². Pour cela, nous mettons la variable price au logarithme. Nous passons donc d'un modèle niveau-niveau à un modèle log-niveau. 

```{r}
lm = lm(log(price) ~ bedrooms + bathrooms + sqft_living + sqft_lot + floors + condition + grade + sqft_basement + yr_built + yr_renovated + zipcode + lat + long + sqft_living15 + sqft_lot15   , data = data)
```

```{r}
summary(lm)
```

# Analyse de la régression 3 

### *Les coefficients*

Comme pour les régressions précédentes toutes les variables ont une influence sur le prix des logements car dans tous les cas <span style="color:purple">**p-value < alpha **</span>. 
Nous pouvons l'interpréter en disant qu'une augmentation de 1 de la variable floors (un étage en plus) augmentera le prix de 7.923%. Ou encore qu'une salle de bain en plus (bathrooms) modifiera le prix du logement de 7.114%. 

### *R²*

La qualité d'ajustement de ce modèle vaut **0.757**, ce qui est assez proche de 1.


### *Significativé globale du modèle* 

<span style="color:purple">**p-value < 2.2e-16 < alpha = 0.01**</span>

Le modèle est globalement significatif. 

### *Les résidus* 

```{r, fig.height = 6, fig.width = 10}
par(mfrow=c(2,2))
plot(lm)
```

- *Normalité*

```{r}
pearson.test(lm$residuals)
```

<span style="color:purple">**p-value < 2.2e-16 < alpha = 0.01**</span>

Le test et le graphique ne permettent pas d'accepter l'hypothèse de normalité des résidus. 

- *Homoscédasticité*

```{r}
bptest(lm)
```

<span style="color:purple">**p-value < 2.2e-16 < alpha = 0.01**</span>

Les résidus ne sont toujours pas homoscédastiques. 

- *Linéarité*

Sur le graphique "Residuals vs Fitted", les résidus sont plus éparpillés que pour les modèles précédents, il y a donc une distribution plus aléatoire. 

- *Valeurs aberrantes*

```{r}
plot(lm,4)
```

Nous avons 5 valeurs qui peuvent sembler aberrantes. 

### *Conclusion* 

```{r}
model_performance(lm)
```

Les valeurs du AIC, BIC et RMSE sont bien plus faible que pour les modèles précédents, ce qui veut dire que l'ajustement est meilleur. 


# Spécification du modèle 2 

Nous avons essayer de modifier la base de données en enlevant les valeurs aberrantes. 

```{r}
newdata1 <- data2[-boxplot.stats(data2$price)$out, ]
newdata2 <- newdata1[-boxplot.stats(newdata1$bedrooms)$out, ]
newdata3 <- newdata2[-boxplot.stats(newdata2$bathrooms)$out, ]
newdata4 <- newdata3[-boxplot.stats(newdata3$sqft_living)$out, ]
newdata5 <- newdata4[-boxplot.stats(newdata4$grade)$out, ]
newdata6 <- newdata5[-boxplot.stats(newdata5$sqft_above)$out, ]
```

Nous nous retrouvons avec une nouvelle base de données composée de 6 variables et d'environ 21164 valeurs (500 de moins qu'au début). 

### *Régression 4*

Cette régression est faite avec la nouvelle base de données. De plus, nous choisissons de mettre le prix en logartihme. 

```{r}
lm2 <- lm(formula = log(price) ~ bedrooms + bathrooms + sqft_living + grade + sqft_above, data = newdata6)
```

```{r}
summary(lm2)
```

# Analyse de la régression 4 

### *Coefficients, R² et significativité*

Les conclusions pour les coefficients et la significativité sont identiques que pour les autres modèles. 

Le R² est de **0.5671**. Il est un peu plus élevé que pour le modèle 1 (qui comportait les mêmes variables) mais est plus faible que pour le modèle 3. Cela est certainement dû au fait qu'un nombre inférieur de variables a été utilisé ici.

### *Les résidus* 

```{r, fig.height = 6, fig.width = 10}
par(mfrow=c(2,2))
plot(lm2)
```

```{r}
pearson.test(lm2$residuals)
```

```{r}
bptest(lm2)
```

Les résultats des tests de normalité et d'homoscédasticité sont identiques aux modèles précédents. 
Cependant, nous pouvons voir grâce aux graphiques que les données se rapprochent plus d'une distribution normale, car les points sont presque entièrement alignés sur la droite (voir graphique "Normal Q-Q"). 
La distribution est aussi plus aléatoire qu'avant car sur le graphique "Residuals vs Fitted" le nuage de points est plus étendu. 


```{r}
plot(lm2, 4)
```

Ce dernier graphique nous montre également qu'il y a beaucoup moins de valeurs aberrantes et les distances de Cook sont beaucoup plus faibles qu'auparavant. 

### *Conclusion*

Les résultats ne sont pas acceptés. Mais les conclusions sur les résidus sont meilleurs que pour les modèles 1,2 et 3. 

# Test 

Nous savons qu'il est possible de faire avec la méthode "Stepwise regression". 

```{r, eval = FALSE}
backward<- lm(log(price) ~ bedrooms + bathrooms + sqft_living + sqft_lot + floors + condition + grade + sqft_basement + yr_built + yr_renovated + zipcode + lat + long + sqft_living15 + sqft_lot15, data = na.omit(data))
step(backward, direction = "backward", trace=FALSE )
stp_b<- ols_step_both_p(backward, pent=0.01, prem=0.05, details=TRUE)
```

# Conclusion 

Il semble évident de dire que la plupart des variables de la base de données, telles que bedroomms, bathrooms, sqft_living ou encore sqft_above, ont un impact certain sur le prix de vente des maisons.

Cependant, aucun des modèles effectués ci-dessus ne permet de confirmer cette hypothèse à cause des résidus.

Mais, nous pouvons quand même dire que mettre le prix au logarithme et retirer les valeurs aberrantes permet d'obtenir un modèle plus performant et des résultats plus proches de la réalité. 

